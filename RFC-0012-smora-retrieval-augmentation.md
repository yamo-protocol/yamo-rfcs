# RFC-0012: S-MORA Retrieval Augmentation

**Status:** Draft
**Author:** Soverane Labs & Collaborative Swarm
**Created:** 2026-02-18
**Depends on:** RFC-0011 (Memory Mesh), RFC-0005 (Singularity Protocol)

---

## Summary

This RFC specifies **S-MORA** (Singularity Memory-Oriented Retrieval Augmentation), a 5-layer RAG pipeline for the YAMO OS. S-MORA extends the base hybrid vector+keyword search of RFC-0011 with query expansion (HyDE-Lite), multi-source retrieval, cross-encoder reranking, and a heritage-aware synthesis stage. The pipeline is designed to operate locally-first with graceful cloud fallback.

---

## Motivation

RFC-0011's Reciprocal Rank Fusion (RRF) search performs well for exact recall but degrades on:
- **Lexical gap** — query uses different words than stored content
- **Short queries** — insufficient signal for vector embedding
- **Heritage-blind retrieval** — ignores intent chains when ranking

S-MORA closes these gaps without requiring external API dependencies in the default configuration.

---

## Specification

### Layer 0 — Pre-Retrieval Scrubbing

All queries pass through the Layer 0 Scrubber (RFC-0011 §5) before embedding. This normalises whitespace, strips HTML, and collapses boilerplate. The scrubbed query is used for all downstream layers.

```
raw_query → Scrubber → scrubbed_query
```

### Layer 1 — HyDE-Lite Query Expansion

**Hypothetical Document Embedding (HyDE-Lite)** generates a synthetic "answer document" from the query using a lightweight template (no LLM required in base mode):

```
hyp_doc = f"[CONTEXT] {scrubbed_query} [ANSWER] {extract_noun_phrases(scrubbed_query)} is relevant because ..."
hyp_embedding = embed(hyp_doc)
```

When an LLM provider is available (`YAMO_ENABLE_LLM=true`), the synthetic document is generated by a single-shot LLM prompt instead:

```
prompt: "Write a 2-sentence answer to: {scrubbed_query}"
hyp_doc = llm.generate(prompt, max_tokens=120)
```

Both the original query embedding and the HyDE embedding are produced. Retrieval uses both (see Layer 2).

### Layer 2 — Multi-Source Retrieval

Three retrieval channels run in parallel:

| Channel | Method | Weight |
|---------|--------|--------|
| Semantic (original) | cosine similarity, query embedding | 1.0 |
| Semantic (HyDE) | cosine similarity, HyDE embedding | 0.8 |
| Keyword (BM25) | term frequency / inverse doc frequency | 0.6 |

Each channel returns up to `retrieval_limit` (default: 30) candidates. Results are merged into a candidate pool (deduped by ID).

### Layer 3 — Reciprocal Rank Fusion (RRF k=60)

The three ranked lists are fused using RFC-0011's RRF algorithm:

```
score(doc) = Σ_channel( weight_channel / (k + rank_channel(doc)) )
```

where `k = 60` and weight values are from Layer 2. Documents absent from a channel contribute 0 to that channel's term.

Top `pre_rerank_limit` (default: 20) candidates are forwarded to Layer 4.

### Layer 4 — Heritage-Aware Reranking

Candidates are reranked by a **cross-encoder score** composed of three signals:

```
final_score(doc) = α × semantic_sim + β × heritage_bonus + γ × recency_decay
```

Where:
- `α = 0.6` — semantic similarity (cosine of query vs doc embedding)
- `β = 0.25` — heritage bonus: `1.0` if `doc.heritage_chain.intentChain` overlaps current session intent, else `0.0`
- `γ = 0.15` — recency: `exp(-λ × age_days)` with `λ = 0.05` (half-life ≈ 14 days)

The heritage bonus requires the caller to provide `sessionIntent: string[]` in the query options. If not provided, `β` contribution is `0` and weights renormalize to `α=0.71, γ=0.29`.

#### Heritage Overlap Calculation

```typescript
function heritageBonus(doc, sessionIntent): number {
  const chain = doc.metadata?.heritage_chain?.intentChain ?? [];
  const overlap = chain.filter(i => sessionIntent.includes(i)).length;
  return overlap > 0 ? Math.min(1.0, overlap / sessionIntent.length) : 0;
}
```

### Layer 5 — Synthesis (Optional)

When `enableSynthesis: true` is passed, the top-k reranked results are passed to a synthesis prompt:

```
You are a retrieval synthesis agent. Given the following memory excerpts, produce a coherent summary that directly answers the query.
Query: {scrubbed_query}
Excerpts: {top_k_results}
```

The synthesis result is returned alongside the ranked result list. When LLM is unavailable, Layer 5 is skipped and raw results are returned.

---

## API Contract

```typescript
interface SMORAOptions {
  limit?: number;           // final top-k (default: 10)
  retrievalLimit?: number;  // per-channel candidates (default: 30)
  sessionIntent?: string[]; // for heritage bonus
  enableSynthesis?: boolean;// run Layer 5 (default: false)
  enableHyDE?: boolean;     // run Layer 1 (default: true)
  useCache?: boolean;       // result cache (default: true)
}

interface SMORAResult {
  id: string;
  content: string;
  metadata: Record<string, unknown>;
  score: number;            // Layer 4 final_score
  semanticScore: number;
  heritageBonus: number;
  recencyDecay: number;
  rrfRank: number;          // rank after Layer 3
}

interface SMORAResponse {
  results: SMORAResult[];
  synthesis?: string;       // Layer 5 output, if enabled
  pipeline: {
    queryExpanded: boolean;
    heritageAware: boolean;
    synthesized: boolean;
    latencyMs: number;
  };
}

// MemoryMesh method
mesh.smora(query: string, options?: SMORAOptions): Promise<SMORAResponse>
```

---

## Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `SMORA_RETRIEVAL_LIMIT` | `30` | Candidates per channel |
| `SMORA_PRE_RERANK_LIMIT` | `20` | Candidates forwarded to Layer 4 |
| `SMORA_HERITAGE_BETA` | `0.25` | Heritage bonus weight |
| `SMORA_RECENCY_LAMBDA` | `0.05` | Recency decay rate |
| `SMORA_HYDE_ENABLED` | `true` | Enable HyDE-Lite expansion |
| `SMORA_SYNTHESIS_ENABLED` | `false` | Enable Layer 5 synthesis |

---

## Integration with RFC-0011

S-MORA is a superset of RFC-0011's `search()`. The `search()` method remains unchanged. S-MORA is exposed as a separate `smora()` method to allow callers to opt into the enhanced pipeline.

The `queryLessons()` method from RFC-0011 should use S-MORA internally when `SMORA_ENABLED=true` with `sessionIntent` derived from lesson metadata's `applicable_scope`.

---

## CLI

```bash
memory-mesh smora "authentication patterns" \
  --limit 5 \
  --session-intent "auth,security,token" \
  --synthesize
```

---

## Performance Characteristics

| Pipeline stage | Added latency | Notes |
|---------------|--------------|-------|
| Layer 1 HyDE (template) | ~2ms | String interpolation only |
| Layer 1 HyDE (LLM) | ~800–2000ms | Network + inference |
| Layer 2 parallel retrieval | +0ms | Concurrent LanceDB queries |
| Layer 3 RRF | ~1ms | In-memory sort |
| Layer 4 reranking | ~5ms | Arithmetic over candidates |
| Layer 5 synthesis | ~1000–3000ms | LLM inference |

Target end-to-end latency (no LLM): < 50ms for up to 1000 stored memories.

---

## Backwards Compatibility

- `search()` is unmodified
- S-MORA is additive; no schema changes required
- Heritage bonus gracefully degrades to 0 when `heritage_chain` is absent

---

## Security Considerations

- Query content passes through Layer 0 scrubber before embedding — PII is removed
- HyDE synthetic documents are never persisted
- Synthesis prompts include only stored memory content, not raw user input post-scrubbing

---

## Reference Implementation

Target files:
- `lib/memory/smora.ts` (pipeline orchestrator)
- `lib/memory/memory-mesh.ts` — add `smora()` public method
- `bin/memory_mesh.js` — add `smora` CLI command
- `test/unit/smora.test.ts` — TDD test suite

---

## Copyright

Copyright and related rights waived via [MIT License](https://opensource.org/licenses/MIT).
